{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b9ead8046fc74db1bf0eb99287c3c91e","deepnote_cell_type":"markdown"},"source":["![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"ca18b36a3bd54ad09e518c5b63b08ef6","deepnote_cell_type":"markdown"},"source":["# Proyecto: Riesgo en el Banco Giturra\n","\n","**MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n","\n","### Cuerpo Docente:\n","\n","- Profesor: Pablo Badilla, Ignacio Meza De La Jara\n","- Auxiliar: Sebastián Tinoco\n","- Ayudante: Diego Cortez M., Felipe Arias T.\n","\n","_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n","\n","---\n","\n","## Reglas\n","\n","- Fecha de entrega: 01/06/2021\n","- **Grupos de 2 personas.**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n","- Estrictamente prohibida la copia.\n","- Pueden usar cualquier material del curso que estimen conveniente.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"20bff171d2954732b74d8f532c21895a","deepnote_cell_type":"markdown"},"source":["---\n"]},{"cell_type":"markdown","metadata":{"cell_id":"731884b83ce840b1b52d26a180626317","deepnote_cell_type":"markdown"},"source":["- Nombre de alumno 1: Sebastián Versluys\n","- Nombre de alumno 2: Josué Guillen"]},{"cell_type":"markdown","metadata":{},"source":["### **Link de repositorio de GitHub:** `https://github.com/Nietsabas/MDS7202`"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introducción "]},{"cell_type":"markdown","metadata":{},"source":["### Descripción del problema"]},{"cell_type":"markdown","metadata":{},"source":["El problema planteado implica desarrollar un modelo predictivo de riesgo crediticio para el banco de Giturra. El objetivo es predecir la probabilidad de que los clientes que soliciten préstamos no cumplan con los pagos acordados. Para lograr esto, se utilizará una amplia variedad de variables relacionadas con los usuarios, como historiales de crédito, ingresos y otros factores financieros relevantes.\n","\n","El propósito del modelo es proporcionar al banco una herramienta que les permita evaluar el nivel de riesgo asociado con cada cliente y cada préstamo específico. Al tener una estimación de la probabilidad de incumplimiento de cada cliente, el banco podrá tomar decisiones más informadas sobre si aprobar o rechazar un préstamo y también ajustar las condiciones del préstamo para mitigar los riesgos potenciales.\n","\n","Es importante que el modelo sea interpretable, lo que significa que debe ser fácilmente comprensible y explicativo para el equipo de Giturra. Esto permitirá que se pueda identificar las variables más influyentes en la predicción de riesgo y que el equipo del banco Giturra puede entender cómo se toman las decisiones crediticias basadas en estas variables."]},{"cell_type":"markdown","metadata":{},"source":["### Descripción variables dadas en contexto"]},{"cell_type":"markdown","metadata":{},"source":["Los datos de entrada proporcionados para el problema de riesgo crediticio incluyen información sobre los clientes que solicitan préstamos al banco. Estos datos abarcan variables como historial crediticio e ingresos\n","\n","- Historial crediticio: Esta variable proporciona información sobre el comportamiento crediticio pasado de los clientes, incluyendo si han realizado pagos a tiempo, si tienen deudas pendientes, si han tenido historial de crédito negativo, etc. Un buen historial crediticio suele ser indicativo de un menor riesgo de incumplimiento.\n","\n","- Ingresos: Estas variables incluyen datos relacionados con los ingresos mensuales de los clientes, sus activos financieros. A priori se podría pensar que un mayor ingreso o mejor situación financiera suelen implicar una mayor capacidad para cumplir con los pagos del préstamo.\n","\n","También según el contexto del problema que tiene banco Giturra existen otras variables relevantes, estas podrían ser a priori (sin haber visto el dataset): información personal del cliente (edad, estado civil, número de dependientes, antigüedad laboral), características del préstamo (monto, plazo, tasa de interés, tipo de préstamo), variables socioeconómicas (nivel educativo, ubicación geográfica, sector laboral). Estos datos en conjunto con los ya brindados (ingresos, historial crediticio) pueden ser fundamentales para evaluar la estabilidad financiera y capacidad de pago del cliente, así como para estimar el riesgo asociado al préstamo y tomar decisiones informadas en el proceso de concesión de préstamos, sin embargo en las siguientes secciones se verá si contamos con este tipo de datos."]},{"cell_type":"markdown","metadata":{},"source":["### Métrica relevante"]},{"cell_type":"markdown","metadata":{},"source":["Para evaluar los modelos generados en el problema de riesgo crediticio, se utilizará el F1-score, enfocándose específicamente en la clase de préstamos impagados debido al desbalanceo de clases en los datos. El F1-score es una métrica que combina precisión y recall, lo que lo hace adecuado para abordar el desafío de clasificar correctamente los préstamos impagados, evitando tanto falsos positivos como falsos negativos y permitiendo tomar decisiones más informadas para reducir el riesgo crediticio."]},{"cell_type":"markdown","metadata":{},"source":["## 2. Carga de datos y Análisis Exploratorio de Datos"]},{"cell_type":"markdown","metadata":{},"source":["### Carga de dataset"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>age</th>\n","      <th>occupation</th>\n","      <th>annual_income</th>\n","      <th>monthly_inhand_salary</th>\n","      <th>num_bank_accounts</th>\n","      <th>num_credit_card</th>\n","      <th>interest_rate</th>\n","      <th>num_of_loan</th>\n","      <th>delay_from_due_date</th>\n","      <th>...</th>\n","      <th>num_credit_inquiries</th>\n","      <th>outstanding_debt</th>\n","      <th>credit_utilization_ratio</th>\n","      <th>credit_history_age</th>\n","      <th>payment_of_min_amount</th>\n","      <th>total_emi_per_month</th>\n","      <th>amount_invested_monthly</th>\n","      <th>payment_behaviour</th>\n","      <th>monthly_balance</th>\n","      <th>credit_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CUS_0xd40</td>\n","      <td>23.0</td>\n","      <td>Scientist</td>\n","      <td>19114.12</td>\n","      <td>1824.843333</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>809.98</td>\n","      <td>23.933795</td>\n","      <td>NaN</td>\n","      <td>No</td>\n","      <td>49.574949</td>\n","      <td>24.785217</td>\n","      <td>High_spent_Medium_value_payments</td>\n","      <td>358.124168</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CUS_0x21b1</td>\n","      <td>28.0</td>\n","      <td>Teacher</td>\n","      <td>34847.84</td>\n","      <td>3037.986667</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>605.03</td>\n","      <td>32.933856</td>\n","      <td>27.0</td>\n","      <td>No</td>\n","      <td>18.816215</td>\n","      <td>218.904344</td>\n","      <td>Low_spent_Small_value_payments</td>\n","      <td>356.078109</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CUS_0x2dbc</td>\n","      <td>34.0</td>\n","      <td>Engineer</td>\n","      <td>143162.64</td>\n","      <td>12187.220000</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>3.0</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>3.0</td>\n","      <td>1303.01</td>\n","      <td>38.374753</td>\n","      <td>18.0</td>\n","      <td>No</td>\n","      <td>246.992319</td>\n","      <td>10000.000000</td>\n","      <td>High_spent_Small_value_payments</td>\n","      <td>895.494583</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CUS_0xb891</td>\n","      <td>55.0</td>\n","      <td>Entrepreneur</td>\n","      <td>30689.89</td>\n","      <td>2612.490833</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>-100.0</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>632.46</td>\n","      <td>27.332515</td>\n","      <td>17.0</td>\n","      <td>No</td>\n","      <td>16.415452</td>\n","      <td>125.617251</td>\n","      <td>High_spent_Small_value_payments</td>\n","      <td>379.216381</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CUS_0x1cdb</td>\n","      <td>21.0</td>\n","      <td>Developer</td>\n","      <td>35547.71</td>\n","      <td>2853.309167</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>-100.0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>943.86</td>\n","      <td>25.862922</td>\n","      <td>31.0</td>\n","      <td>Yes</td>\n","      <td>0.000000</td>\n","      <td>181.330901</td>\n","      <td>High_spent_Small_value_payments</td>\n","      <td>364.000016</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>"],"text/plain":["  customer_id   age    occupation  annual_income  monthly_inhand_salary  \\\n","0   CUS_0xd40  23.0     Scientist       19114.12            1824.843333   \n","1  CUS_0x21b1  28.0       Teacher       34847.84            3037.986667   \n","2  CUS_0x2dbc  34.0      Engineer      143162.64           12187.220000   \n","3  CUS_0xb891  55.0  Entrepreneur       30689.89            2612.490833   \n","4  CUS_0x1cdb  21.0     Developer       35547.71            2853.309167   \n","\n","   num_bank_accounts  num_credit_card  interest_rate  num_of_loan  \\\n","0                  3                4              3          4.0   \n","1                  2                4              6          1.0   \n","2                  1                5              8          3.0   \n","3                  2                5              4       -100.0   \n","4                  7                5              5       -100.0   \n","\n","   delay_from_due_date  ...  num_credit_inquiries  outstanding_debt  \\\n","0                    3  ...                   4.0            809.98   \n","1                    3  ...                   2.0            605.03   \n","2                    8  ...                   3.0           1303.01   \n","3                    4  ...                   4.0            632.46   \n","4                    1  ...                   4.0            943.86   \n","\n","   credit_utilization_ratio  credit_history_age  payment_of_min_amount  \\\n","0                 23.933795                 NaN                     No   \n","1                 32.933856                27.0                     No   \n","2                 38.374753                18.0                     No   \n","3                 27.332515                17.0                     No   \n","4                 25.862922                31.0                    Yes   \n","\n","   total_emi_per_month amount_invested_monthly  \\\n","0            49.574949               24.785217   \n","1            18.816215              218.904344   \n","2           246.992319            10000.000000   \n","3            16.415452              125.617251   \n","4             0.000000              181.330901   \n","\n","                  payment_behaviour  monthly_balance credit_score  \n","0  High_spent_Medium_value_payments       358.124168            0  \n","1    Low_spent_Small_value_payments       356.078109            0  \n","2   High_spent_Small_value_payments       895.494583            0  \n","3   High_spent_Small_value_payments       379.216381            0  \n","4   High_spent_Small_value_payments       364.000016            0  \n","\n","[5 rows x 22 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","df = pd.read_parquet(\"dataset.pq\")\n","df.head(5)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>annual_income</th>\n","      <th>monthly_inhand_salary</th>\n","      <th>num_bank_accounts</th>\n","      <th>num_credit_card</th>\n","      <th>interest_rate</th>\n","      <th>num_of_loan</th>\n","      <th>delay_from_due_date</th>\n","      <th>num_of_delayed_payment</th>\n","      <th>changed_credit_limit</th>\n","      <th>num_credit_inquiries</th>\n","      <th>outstanding_debt</th>\n","      <th>credit_utilization_ratio</th>\n","      <th>credit_history_age</th>\n","      <th>total_emi_per_month</th>\n","      <th>amount_invested_monthly</th>\n","      <th>monthly_balance</th>\n","      <th>credit_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>12500.000000</td>\n","      <td>1.250000e+04</td>\n","      <td>10584.000000</td>\n","      <td>12500.000000</td>\n","      <td>12500.000000</td>\n","      <td>12500.000000</td>\n","      <td>12500.000000</td>\n","      <td>12500.000000</td>\n","      <td>11660.00000</td>\n","      <td>12246.000000</td>\n","      <td>12243.000000</td>\n","      <td>12500.000000</td>\n","      <td>12500.000000</td>\n","      <td>11380.000000</td>\n","      <td>12500.000000</td>\n","      <td>11914.000000</td>\n","      <td>1.214500e+04</td>\n","      <td>12500.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>105.771840</td>\n","      <td>1.616206e+05</td>\n","      <td>4186.634963</td>\n","      <td>16.939920</td>\n","      <td>23.172720</td>\n","      <td>73.213360</td>\n","      <td>3.099440</td>\n","      <td>21.060880</td>\n","      <td>32.93542</td>\n","      <td>10.398582</td>\n","      <td>26.292330</td>\n","      <td>1426.220376</td>\n","      <td>32.349265</td>\n","      <td>18.230404</td>\n","      <td>1488.394291</td>\n","      <td>638.798715</td>\n","      <td>-2.744614e+22</td>\n","      <td>0.288160</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>664.502705</td>\n","      <td>1.297842e+06</td>\n","      <td>3173.690362</td>\n","      <td>114.350815</td>\n","      <td>132.005866</td>\n","      <td>468.682227</td>\n","      <td>65.105277</td>\n","      <td>14.863091</td>\n","      <td>237.43768</td>\n","      <td>6.799253</td>\n","      <td>181.821031</td>\n","      <td>1155.169458</td>\n","      <td>5.156815</td>\n","      <td>8.302078</td>\n","      <td>8561.449910</td>\n","      <td>2049.195193</td>\n","      <td>3.024684e+24</td>\n","      <td>0.452924</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-500.000000</td>\n","      <td>7.005930e+03</td>\n","      <td>303.645417</td>\n","      <td>-1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>-100.000000</td>\n","      <td>-5.000000</td>\n","      <td>-3.00000</td>\n","      <td>-6.490000</td>\n","      <td>0.000000</td>\n","      <td>0.230000</td>\n","      <td>20.100770</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-3.333333e+26</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>25.000000</td>\n","      <td>1.945333e+04</td>\n","      <td>1622.408646</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>8.000000</td>\n","      <td>1.000000</td>\n","      <td>10.000000</td>\n","      <td>9.00000</td>\n","      <td>5.370000</td>\n","      <td>4.000000</td>\n","      <td>566.072500</td>\n","      <td>28.066517</td>\n","      <td>12.000000</td>\n","      <td>31.496968</td>\n","      <td>73.736810</td>\n","      <td>2.701501e+02</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>33.000000</td>\n","      <td>3.757238e+04</td>\n","      <td>3087.595000</td>\n","      <td>6.000000</td>\n","      <td>5.000000</td>\n","      <td>14.000000</td>\n","      <td>3.000000</td>\n","      <td>18.000000</td>\n","      <td>14.00000</td>\n","      <td>9.410000</td>\n","      <td>6.000000</td>\n","      <td>1166.155000</td>\n","      <td>32.418953</td>\n","      <td>18.000000</td>\n","      <td>72.887628</td>\n","      <td>134.093193</td>\n","      <td>3.393885e+02</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>42.000000</td>\n","      <td>7.269021e+04</td>\n","      <td>5967.937500</td>\n","      <td>7.000000</td>\n","      <td>7.000000</td>\n","      <td>20.000000</td>\n","      <td>5.000000</td>\n","      <td>28.000000</td>\n","      <td>18.00000</td>\n","      <td>14.940000</td>\n","      <td>10.000000</td>\n","      <td>1945.962500</td>\n","      <td>36.623650</td>\n","      <td>25.000000</td>\n","      <td>169.634826</td>\n","      <td>261.664256</td>\n","      <td>4.714245e+02</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>8678.000000</td>\n","      <td>2.383470e+07</td>\n","      <td>15204.633333</td>\n","      <td>1756.000000</td>\n","      <td>1499.000000</td>\n","      <td>5789.000000</td>\n","      <td>1495.000000</td>\n","      <td>67.000000</td>\n","      <td>4293.00000</td>\n","      <td>36.970000</td>\n","      <td>2554.000000</td>\n","      <td>4998.070000</td>\n","      <td>48.199824</td>\n","      <td>33.000000</td>\n","      <td>81971.000000</td>\n","      <td>10000.000000</td>\n","      <td>1.463792e+03</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                age  annual_income  monthly_inhand_salary  num_bank_accounts  \\\n","count  12500.000000   1.250000e+04           10584.000000       12500.000000   \n","mean     105.771840   1.616206e+05            4186.634963          16.939920   \n","std      664.502705   1.297842e+06            3173.690362         114.350815   \n","min     -500.000000   7.005930e+03             303.645417          -1.000000   \n","25%       25.000000   1.945333e+04            1622.408646           3.000000   \n","50%       33.000000   3.757238e+04            3087.595000           6.000000   \n","75%       42.000000   7.269021e+04            5967.937500           7.000000   \n","max     8678.000000   2.383470e+07           15204.633333        1756.000000   \n","\n","       num_credit_card  interest_rate   num_of_loan  delay_from_due_date  \\\n","count     12500.000000   12500.000000  12500.000000         12500.000000   \n","mean         23.172720      73.213360      3.099440            21.060880   \n","std         132.005866     468.682227     65.105277            14.863091   \n","min           0.000000       1.000000   -100.000000            -5.000000   \n","25%           4.000000       8.000000      1.000000            10.000000   \n","50%           5.000000      14.000000      3.000000            18.000000   \n","75%           7.000000      20.000000      5.000000            28.000000   \n","max        1499.000000    5789.000000   1495.000000            67.000000   \n","\n","       num_of_delayed_payment  changed_credit_limit  num_credit_inquiries  \\\n","count             11660.00000          12246.000000          12243.000000   \n","mean                 32.93542             10.398582             26.292330   \n","std                 237.43768              6.799253            181.821031   \n","min                  -3.00000             -6.490000              0.000000   \n","25%                   9.00000              5.370000              4.000000   \n","50%                  14.00000              9.410000              6.000000   \n","75%                  18.00000             14.940000             10.000000   \n","max                4293.00000             36.970000           2554.000000   \n","\n","       outstanding_debt  credit_utilization_ratio  credit_history_age  \\\n","count      12500.000000              12500.000000        11380.000000   \n","mean        1426.220376                 32.349265           18.230404   \n","std         1155.169458                  5.156815            8.302078   \n","min            0.230000                 20.100770            0.000000   \n","25%          566.072500                 28.066517           12.000000   \n","50%         1166.155000                 32.418953           18.000000   \n","75%         1945.962500                 36.623650           25.000000   \n","max         4998.070000                 48.199824           33.000000   \n","\n","       total_emi_per_month  amount_invested_monthly  monthly_balance  \\\n","count         12500.000000             11914.000000     1.214500e+04   \n","mean           1488.394291               638.798715    -2.744614e+22   \n","std            8561.449910              2049.195193     3.024684e+24   \n","min               0.000000                 0.000000    -3.333333e+26   \n","25%              31.496968                73.736810     2.701501e+02   \n","50%              72.887628               134.093193     3.393885e+02   \n","75%             169.634826               261.664256     4.714245e+02   \n","max           81971.000000             10000.000000     1.463792e+03   \n","\n","       credit_score  \n","count  12500.000000  \n","mean       0.288160  \n","std        0.452924  \n","min        0.000000  \n","25%        0.000000  \n","50%        0.000000  \n","75%        1.000000  \n","max        1.000000  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["(12500, 22)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Preparación de datos"]},{"cell_type":"markdown","metadata":{},"source":["Antes de empezar el column transformer es prudente y necesario tratar errores de imputación u outliers relevantes a eliminar, para ello lo primero que se hará será filtrar las muestras para edades en torno a los 14 y 100 años, este rango se define viendo el EDA que sale en el profile, pues se puede notar que los 5 valores mínimos con menor aparición en este variable es -500 con un 0.8% por lo que esto claramente es un error de imputación así que debe ir fuera de este filtro, por otro lado el segundo valor mínimo es 14 que en general es la edad mínima para que un adolescente puede entrar al sistema financiero en muchos paises por lo que tiene sentido para usarlo como cota mínima, por otro lado como cota máxima se usa 100 años que es una edad prudente ya que clientes mayores a esa edad o están muertos o no tienen mucho valor para el banco."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#Filtrando muestras con edades en torno a 14 y 100 años\n","\n","df = df[(df['age'] >= 14) & (df['age'] <= 100)]"]},{"cell_type":"markdown","metadata":{},"source":["También se encontraron cantidades extremadamente altas que no corresponden a la naturaleza de la variable por ejemplo un valor extremadamente alto de `interest_rate`, en el dataset df esta variable no esta en porcentaje si no en un número que apriori deberia ser mayor a 0 y menor a 100, es imposible que se cobren tasas de interés superiores inclusivo a cotas como 30 o 50, esto ya que el sistema bancario siempre ha estado regulado, por lo que va1ores superiores a este se consideran outliers o mala inputación de valores, sin embargo para ser más objetivos se eliminaran valores superiores a 100, que sería tasas mayores a 100%."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["df = df[df['interest_rate'] <= 100]"]},{"cell_type":"markdown","metadata":{},"source":["Del EDA del profile se puede notar que existen valores negativos en cantidades, como valor negativo en cuentas de banco (`num_bank_accounts`), número de préstamos (`num_of_loan`), `delay_from_due_date` que apriori no puede ser negativo ya que es el promedio de días de retraso desde la fecha de pago, de la misma manera para `num_of_delayed_payment` no puede haber un promedio negativo de pagos atrasados ​​por una persona, a priori se podría pensar que el `changed_credit_limit` no podría ser negativo pero esta variable que representa el cambio porcentual en el límite de la tarjeta de crédito podría ser negativo si se disminuye el límite a los créditos de una persona (que por experiencia podría pasar cuando se tiene un comportamiento crediticio malo), "]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["df = df[df['num_of_loan'] >= 0]\n","df = df[df['num_bank_accounts'] >= 0]\n","df = df[df['delay_from_due_date'] >= 0]\n","df = df[df['num_of_delayed_payment'] >= 0]\n"]},{"cell_type":"markdown","metadata":{},"source":["Finalmente, se eliminan variables que no tienen mayor explicabilidad como customer_id notando segun el profile que no existen duplicados en esta variable"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["df = df.drop(columns=['customer_id'])"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["(10528, 21)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","metadata":{},"source":["Notemos que estos filtros son necesarios antes de empezar, además pasamos de 12k a 10.5k es decir una reducción de 12% lo cual no es mucho dada la cantidad de datos que teníamos previamente."]},{"cell_type":"markdown","metadata":{},"source":["### Preprocesamiento con `ColumnTransformer`"]},{"cell_type":"markdown","metadata":{},"source":["Es necesario también convertir las columnas mal leidas a sus tipos correspondientes"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["age                         float64\n","occupation                   object\n","annual_income               float64\n","monthly_inhand_salary       float64\n","num_bank_accounts             int64\n","num_credit_card               int64\n","interest_rate                 int64\n","num_of_loan                 float64\n","delay_from_due_date           int64\n","num_of_delayed_payment      float64\n","changed_credit_limit        float64\n","num_credit_inquiries        float64\n","outstanding_debt            float64\n","credit_utilization_ratio    float64\n","credit_history_age          float64\n","payment_of_min_amount        object\n","total_emi_per_month         float64\n","amount_invested_monthly     float64\n","payment_behaviour            object\n","monthly_balance             float64\n","credit_score                  int64\n","dtype: object"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["df['age'] = df['age'].astype('int64')\n","df['num_of_loan'] = df['num_of_loan'].astype('int64')\n","df['delay_from_due_date'] = df['delay_from_due_date'].astype('float64')"]},{"cell_type":"markdown","metadata":{},"source":["Se cambiaron los tipos de las variables por las siguientes razones:\n","\n","- `age`: Se cambió a tipo `int` porque la edad de una persona generalmente se representa como un número entero, y no tiene sentido tener valores decimales para la edad.\n","- `num_of_loan`: Se cambió a tipo `int` porque la cantidad de préstamos tomados por una persona debe ser un número entero. Los préstamos no se pueden tomar en fracciones.\n","\n","- `delay_from_due_date`: Se cambió a tipo `float` porque la variable representa la cantidad promedio de días de retraso en los pagos, y este valor podría tener decimales si hay retrasos parciales en los pagos.\n","\n","Estos cambios en el tipo de dato garantizan que las variables estén representadas de la manera más adecuada para su posterior análisis y modelado, ya que se alinean mejor con la naturaleza de los datos y sus significados en el contexto del riesgo crediticio."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["age                           int64\n","occupation                   object\n","annual_income               float64\n","monthly_inhand_salary       float64\n","num_bank_accounts             int64\n","num_credit_card               int64\n","interest_rate                 int64\n","num_of_loan                   int64\n","delay_from_due_date         float64\n","num_of_delayed_payment      float64\n","changed_credit_limit        float64\n","num_credit_inquiries        float64\n","outstanding_debt            float64\n","credit_utilization_ratio    float64\n","credit_history_age          float64\n","payment_of_min_amount        object\n","total_emi_per_month         float64\n","amount_invested_monthly     float64\n","payment_behaviour            object\n","monthly_balance             float64\n","credit_score                  int64\n","dtype: object"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]}],"source":["import pandas as pd\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","\n","# Variables numéricas\n","numeric_features = ['age', 'annual_income', 'monthly_inhand_salary', 'num_bank_accounts',\n","                    'num_credit_card', 'interest_rate', 'num_of_loan', 'delay_from_due_date',\n","                    'num_of_delayed_payment', 'changed_credit_limit', 'num_credit_inquiries',\n","                    'outstanding_debt', 'credit_utilization_ratio', 'credit_history_age',\n","                    'total_emi_per_month', 'amount_invested_monthly', 'monthly_balance']\n","\n","# Variables categóricas\n","categorical_features = ['occupation', 'payment_of_min_amount', 'payment_behaviour']\n","\n","# Preprocesamiento de variables numéricas\n","numeric_transformer = StandardScaler()\n","\n","# Preprocesamiento de variables categóricas con OneHotEncoder (sin datos dispersos)\n","categorical_transformer = OneHotEncoder(sparse=False)\n","\n","# Dividir el DataFrame en características (X) y variable objetivo (y)\n","X = df.drop(columns=['credit_score']) \n","y = df['credit_score'] \n","\n","# ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ],\n","    remainder='passthrough'  \n",")\n","\n","# ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ],\n","    remainder='passthrough'  \n",")\n","\n","# Configuramos la salida del preprocesador como un DataFrame de pandas\n","preprocessor.set_output(transform=\"pandas\")\n","\n","X_preprocessed = preprocessor.fit_transform(X)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# Estableciendo semilla aleatoria\n","\n","semilla = 42"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["pandas.core.frame.DataFrame"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["type(X_preprocessed)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['age', 'occupation', 'annual_income', 'monthly_inhand_salary',\n","       'num_bank_accounts', 'num_credit_card', 'interest_rate', 'num_of_loan',\n","       'delay_from_due_date', 'num_of_delayed_payment', 'changed_credit_limit',\n","       'num_credit_inquiries', 'outstanding_debt', 'credit_utilization_ratio',\n","       'credit_history_age', 'payment_of_min_amount', 'total_emi_per_month',\n","       'amount_invested_monthly', 'payment_behaviour', 'monthly_balance',\n","       'credit_score'],\n","      dtype='object')\n"]}],"source":["print(df.columns)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Holdout"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["# Holdout\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=semilla)\n"]},{"cell_type":"markdown","metadata":{},"source":["###  Datos nulos"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["monthly_inhand_salary       0.152451\n","credit_history_age          0.088526\n","amount_invested_monthly     0.046922\n","monthly_balance             0.028210\n","num_credit_inquiries        0.020802\n","changed_credit_limit        0.020327\n","payment_behaviour           0.000000\n","total_emi_per_month         0.000000\n","payment_of_min_amount       0.000000\n","credit_utilization_ratio    0.000000\n","outstanding_debt            0.000000\n","age                         0.000000\n","occupation                  0.000000\n","num_of_delayed_payment      0.000000\n","delay_from_due_date         0.000000\n","num_of_loan                 0.000000\n","interest_rate               0.000000\n","num_credit_card             0.000000\n","num_bank_accounts           0.000000\n","annual_income               0.000000\n","credit_score                0.000000\n","dtype: float64"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["### NaNs\n","\n","porcentajes_nulos = (df.isnull().sum() / len(df))\n","porcentajes_nulos = porcentajes_nulos.sort_values(ascending=False)\n","porcentajes_nulos"]},{"cell_type":"markdown","metadata":{},"source":["Como podemos ver en el profile dado y el código anterior la variable `monthly_inhand_salary` cuenta con un mayor número de NANs, a priori como se comentó en la sección 1 se cree que el salario puede estar involucrado en el riesgo crediticio, por lo que eliminar muestras con NaNs en esta variable puede resultar en un sesgo considerable dado que estos NaNs representan un alto porcentaje (15%) por ende se decide usar otro técnica que no sea el drop de NaNs que es la imputación de la mediana. Lo mismo sucede con `credit_history_age` que a priori puede llegar a tener un fuerte sesgo el eliminar muestras con NaNs en esta variable, por ende se decide realizar una imputación sobre la mediana también. Siguiendo esa linea y dado que el modelo tiene pocas NaNs para las otras variables se decide hacer imputación de mediana finalmente para todas.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Baseline"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Classification Report - Dummy (Stratified):\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.72      0.72      0.72      1488\n","           1       0.32      0.31      0.32       618\n","\n","    accuracy                           0.60      2106\n","   macro avg       0.52      0.52      0.52      2106\n","weighted avg       0.60      0.60      0.60      2106\n","\n","\n","Classification Report - Logistic Regression:\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.91      0.85      1488\n","           1       0.66      0.40      0.50       618\n","\n","    accuracy                           0.76      2106\n","   macro avg       0.72      0.66      0.67      2106\n","weighted avg       0.75      0.76      0.74      2106\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Classification Report - K-Nearest Neighbors:\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.87      0.83      1488\n","           1       0.60      0.46      0.52       618\n","\n","    accuracy                           0.75      2106\n","   macro avg       0.70      0.67      0.68      2106\n","weighted avg       0.74      0.75      0.74      2106\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Classification Report - Decision Tree:\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.77      0.78      1488\n","           1       0.47      0.49      0.48       618\n","\n","    accuracy                           0.69      2106\n","   macro avg       0.63      0.63      0.63      2106\n","weighted avg       0.69      0.69      0.69      2106\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Classification Report - SVM:\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.90      0.85      1488\n","           1       0.65      0.45      0.53       618\n","\n","    accuracy                           0.77      2106\n","   macro avg       0.72      0.67      0.69      2106\n","weighted avg       0.75      0.77      0.75      2106\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Classification Report - Random Forest:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.90      0.86      1488\n","           1       0.69      0.52      0.59       618\n","\n","    accuracy                           0.79      2106\n","   macro avg       0.75      0.71      0.73      2106\n","weighted avg       0.78      0.79      0.78      2106\n","\n","\n","[LightGBM] [Info] Number of positive: 2446, number of negative: 5976\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001485 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2288\n","[LightGBM] [Info] Number of data points in the train set: 8422, number of used features: 43\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290430 -> initscore=-0.893297\n","[LightGBM] [Info] Start training from score -0.893297\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Classification Report - LightGBM:\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.89      0.86      1488\n","           1       0.67      0.55      0.61       618\n","\n","    accuracy                           0.79      2106\n","   macro avg       0.75      0.72      0.73      2106\n","weighted avg       0.78      0.79      0.78      2106\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Classification Report - XGBoost:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.88      0.85      1488\n","           1       0.64      0.53      0.58       618\n","\n","    accuracy                           0.78      2106\n","   macro avg       0.73      0.70      0.71      2106\n","weighted avg       0.77      0.78      0.77      2106\n","\n","\n","F1 Score para cada Clasificador:\n","            Classifier  F1 Score\n","6             LightGBM  0.606383\n","5        Random Forest  0.593205\n","7              XGBoost  0.581045\n","4                  SVM  0.532443\n","2  K-Nearest Neighbors  0.521898\n","1  Logistic Regression  0.498994\n","3        Decision Tree  0.482157\n","0   Dummy (Stratified)  0.315617\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.dummy import DummyClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from lightgbm import LGBMClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, f1_score\n","\n","# Clasificadores a evaluar\n","classifiers = {\n","    'Dummy (Stratified)': DummyClassifier(strategy='stratified', random_state=semilla),\n","    'Logistic Regression': LogisticRegression(random_state=semilla),\n","    'K-Nearest Neighbors': KNeighborsClassifier(),\n","    'Decision Tree': DecisionTreeClassifier(random_state=semilla),\n","    'SVM': SVC(random_state=semilla),\n","    'Random Forest': RandomForestClassifier(random_state=semilla),\n","    'LightGBM': LGBMClassifier(random_state=semilla),\n","    'XGBoost': XGBClassifier(random_state=semilla)\n","}\n","\n","# Creamos un arreglo para almacenar las métricas\n","metrics = []\n","\n","# Pipeline para el imputador promedio (mean imputer)\n","mean_imputer = Pipeline([\n","    ('imputer', SimpleImputer(strategy='mean'))\n","])\n","\n","\n","for clf_name, clf in classifiers.items():\n","    # Creamos el pipeline con el preprocesamiento, imputador promedio y el clasificador\n","    pipeline = Pipeline([\n","        ('preprocessor', preprocessor),\n","        ('imputer', mean_imputer),\n","        ('classifier', clf)\n","    ])\n","    # Entrenamos el modelo\n","    pipeline.fit(X_train, y_train)\n","    \n","    # Evaluamos el modelo en el conjunto de prueba\n","    y_pred = pipeline.predict(X_test)\n","    report = classification_report(y_test, y_pred, output_dict=True)\n","    \n","    # Imprimimos todas las métricas del classification_report\n","    print(f\"Classification Report - {clf_name}:\")\n","    print(classification_report(y_test, y_pred))\n","    print()\n","    \n","    # Almacenamos el f1_score en el DataFrame de métricas\n","    metrics.append({'Classifier': clf_name, 'F1 Score': report['1']['f1-score']})\n","\n","# Creamos un DataFrame con los resultados\n","results_df = pd.DataFrame(metrics)\n","results_df.sort_values(by='F1 Score', ascending=False, inplace=True)\n","print(\"F1 Score para cada Clasificador:\")\n","print(results_df)\n"]},{"cell_type":"markdown","metadata":{},"source":["¿Hay algún clasificador entrenado mejor que el azar (Dummy)?\n","Sí, todos los clasificadores entrenados tienen un F1 Score mayor que el clasificador Dummy, que tiene un F1 Score de aproximadamente 0.290. Esto indica que todos los clasificadores están aprendiendo patrones relevantes en los datos y superan significativamente el rendimiento aleatorio del Dummy.\n","\n","¿Cuál es el mejor clasificador entrenado?\n","El mejor clasificador entrenado es LightGBM, con un F1 Score de aproximadamente 0.606. Esto indica que LightGBM tiene un mejor equilibrio entre precisión y recall, lo que sugiere que puede identificar correctamente a los individuos que tienen un alto riesgo crediticio (clase 1) y también aquellos que no (clase 0).\n","\n","¿Por qué el mejor clasificador es mejor que los otros?\n","LightGBM es un algoritmo de aprendizaje automático basado en árboles de decisión que utiliza el enfoque de \"gradient boosting\". Este método suele ofrecer un rendimiento sólido en muchos conjuntos de datos debido a su eficiencia y capacidad para manejar grandes cantidades de datos y características. También puede manejar datos categóricos sin necesidad de codificación previa. Además, al utilizar \"gradient boosting\", se combinan varios árboles débiles para formar un modelo más robusto y generalizable.\n","\n","El buen rendimiento de LightGBM también puede atribuirse a su capacidad para tratar datos desbalanceados, como en este caso donde puede haber menos ejemplos de clase 1 (personas con mala calificación crediticia) en comparación con la clase 0 (personas con buena calificación crediticia). Los clasificadores basados en árboles tienden a manejar mejor esta situación.\n","\n","Respecto al tiempo de entrenamiento, este suele variar según el tamaño del conjunto de datos, la complejidad del algoritmo y la cantidad de hiperparámetros que se necesitan ajustar. En este caso, dado que el conjunto de datos no parece ser extremadamente grande, los tiempos de entrenamiento no deberían ser un problema significativo para la mayoría de los algoritmos utilizados.\n","\n","Sin embargo, es probable que los algoritmos más lentos sean SVM y K-Nearest Neighbors, ya que SVM busca encontrar el hiperplano óptimo para separar las clases, mientras que K-Nearest Neighbors necesita calcular la distancia entre cada punto del conjunto de prueba y todos los puntos del conjunto de entrenamiento. Estos algoritmos pueden requerir más tiempo de entrenamiento y podrían ser buenos candidatos para experimentar con la optimización de hiperparámetros. Por otro lado, Random Forest, LightGBM y XGBoost son algoritmos más eficientes y pueden ser más rápidos para experimentar con diferentes combinaciones de hiperparámetros. "]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 2446, number of negative: 5976\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 955\n","[LightGBM] [Info] Number of data points in the train set: 8422, number of used features: 10\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290430 -> initscore=-0.893297\n","[LightGBM] [Info] Start training from score -0.893297\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n","c:\\Users\\jos_5\\anaconda3\\envs\\proyecto_2_env\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 5976, number of negative: 5976\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 955\n","[LightGBM] [Info] Number of data points in the train set: 11952, number of used features: 10\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","Classification Report - LightGBM:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.89      0.85      1488\n","           1       0.67      0.53      0.59       618\n","\n","    accuracy                           0.79      2106\n","   macro avg       0.75      0.71      0.72      2106\n","weighted avg       0.78      0.79      0.78      2106\n","\n","\n","Classification Report - Random Forest:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.89      0.85      1488\n","           1       0.66      0.53      0.59       618\n","\n","    accuracy                           0.78      2106\n","   macro avg       0.74      0.71      0.72      2106\n","weighted avg       0.77      0.78      0.78      2106\n","\n","\n","Classification Report - Imbalanced LightGBM:\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.80      0.82      1488\n","           1       0.57      0.63      0.60       618\n","\n","    accuracy                           0.75      2106\n","   macro avg       0.70      0.71      0.71      2106\n","weighted avg       0.76      0.75      0.75      2106\n","\n","\n"]}],"source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.model_selection import GridSearchCV\n","from imblearn.pipeline import Pipeline as ImbalancedPipeline\n","from imblearn.over_sampling import RandomOverSampler\n","\n","# Instanciando nuevas Pipelines para LightGBM y Random Forest con imputador promedio (mean imputer) y selección de atributos\n","lightgbm_pipeline = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('imputer', SimpleImputer(strategy='mean')),\n","    ('feature_selector', SelectKBest(k=10)),  \n","    ('classifier', LGBMClassifier())\n","])\n","\n","randomforest_pipeline = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('imputer', SimpleImputer(strategy='mean')),\n","    ('feature_selector', SelectKBest(k=10)), \n","    ('classifier', RandomForestClassifier())\n","])\n","\n","# Definiendo los rangos de hiperparámetros a buscar para cada modelo\n","param_grid_lightgbm = {\n","    'classifier__n_estimators': [50, 100, 200],  # Definimos aquí los valores a probar para el número de estimadores\n","    'classifier__max_depth': [3, 5, 7],\n","}\n","\n","param_grid_randomforest = {\n","    'classifier__n_estimators': [50, 100, 200],\n","    'classifier__max_depth': [None, 3, 5],\n","}\n","\n","# Búsqueda de hiperparámetros usando GridSearchCV o HalvingGridSearchCV\n","grid_search_lightgbm = GridSearchCV(lightgbm_pipeline, param_grid_lightgbm, scoring='f1', cv=5, n_jobs=-1)\n","grid_search_randomforest = GridSearchCV(randomforest_pipeline, param_grid_randomforest, scoring='f1', cv=5, n_jobs=-1)\n","\n","# Entrenando los modelos con los mejores hiperparámetros encontrados\n","grid_search_lightgbm.fit(X_train, y_train)\n","grid_search_randomforest.fit(X_train, y_train)\n","\n","# Obteniendo los mejores modelos\n","best_lightgbm_model = grid_search_lightgbm.best_estimator_\n","best_randomforest_model = grid_search_randomforest.best_estimator_\n","\n","# Probando técnicas de balanceo de datos\n","imbalanced_lightgbm_pipeline = ImbalancedPipeline([\n","    ('preprocessor', preprocessor),\n","    ('imputer', SimpleImputer(strategy='mean')),\n","    ('feature_selector', SelectKBest(k=10)),  \n","    ('oversampler', RandomOverSampler()), \n","    ('classifier', LGBMClassifier())\n","])\n","\n","imbalanced_lightgbm_pipeline.fit(X_train, y_train)\n","\n","y_pred_lightgbm = best_lightgbm_model.predict(X_test)\n","y_pred_randomforest = best_randomforest_model.predict(X_test)\n","y_pred_imbalanced_lightgbm = imbalanced_lightgbm_pipeline.predict(X_test)\n","\n","report_lightgbm = classification_report(y_test, y_pred_lightgbm, output_dict=True)\n","report_randomforest = classification_report(y_test, y_pred_randomforest, output_dict=True)\n","report_imbalanced_lightgbm = classification_report(y_test, y_pred_imbalanced_lightgbm, output_dict=True)\n","\n","print(\"Classification Report - LightGBM:\")\n","print(classification_report(y_test, y_pred_lightgbm))\n","print()\n","\n","print(\"Classification Report - Random Forest:\")\n","print(classification_report(y_test, y_pred_randomforest))\n","print()\n","\n","print(\"Classification Report - Imbalanced LightGBM:\")\n","print(classification_report(y_test, y_pred_imbalanced_lightgbm))\n","print()\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"4a4ad4306407402db0c258f95d5a9abe","kernelspec":{"display_name":"competencia","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
